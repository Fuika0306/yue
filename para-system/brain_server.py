#!/usr/bin/env python3

"""
Brain Server - è¨˜æ†¶å‘é‡æœå‹™
å¸¸é§å¾Œå°é‹è¡Œï¼ŒæŠŠ MiniLM æ¨¡å‹ä¿æŒåœ¨è¨˜æ†¶é«”ä¸­
å…¶ä»–è…³æœ¬é€é HTTP è«‹æ±‚ä¾†ç·¨ç¢¼å’Œæª¢ç´¢
"""

from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from sentence_transformers import SentenceTransformer
import json
import os
from typing import List, Dict, Any
import logging

# é…ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(title="Brain Server", version="1.0")

# å…¨å±€æ¨¡å‹ï¼ˆå•Ÿå‹•æ™‚åŠ è¼‰ä¸€æ¬¡ï¼‰
model = None

class EncodeRequest(BaseModel):
    texts: List[str]

class EncodeResponse(BaseModel):
    embeddings: List[List[float]]
    count: int

class RetrieveRequest(BaseModel):
    query: str
    memories: List[Dict[str, Any]]
    top_k: int = 5
    threshold: float = 0.5

class RetrieveResponse(BaseModel):
    results: List[Dict[str, Any]]
    count: int

@app.on_event("startup")
async def startup_event():
    """å•Ÿå‹•æ™‚åŠ è¼‰æ¨¡å‹"""
    global model
    logger.info("ğŸ§  Brain Server å•Ÿå‹•ä¸­...")
    try:
        model = SentenceTransformer('all-MiniLM-L6-v2')
        logger.info("âœ… å‘é‡æ¨¡å‹å·²åŠ è¼‰åˆ°è¨˜æ†¶é«”")
    except Exception as e:
        logger.error(f"âŒ æ¨¡å‹åŠ è¼‰å¤±æ•—: {e}")
        raise

@app.on_event("shutdown")
async def shutdown_event():
    """é—œé–‰æ™‚æ¸…ç†"""
    logger.info("ğŸ›‘ Brain Server é—œé–‰ä¸­...")

@app.get("/health")
async def health_check():
    """å¥åº·æª¢æŸ¥"""
    return {
        "status": "ok",
        "model_loaded": model is not None,
        "service": "Brain Server v1.0"
    }

@app.post("/encode", response_model=EncodeResponse)
async def encode(request: EncodeRequest):
    """
    ç·¨ç¢¼æ–‡æœ¬ç‚ºå‘é‡
    
    è¼¸å…¥ï¼š
    {
        "texts": ["æ–‡æœ¬1", "æ–‡æœ¬2", ...]
    }
    
    è¼¸å‡ºï¼š
    {
        "embeddings": [[...], [...], ...],
        "count": 2
    }
    """
    if model is None:
        raise HTTPException(status_code=503, detail="æ¨¡å‹æœªåŠ è¼‰")
    
    try:
        embeddings = model.encode(request.texts, convert_to_tensor=False)
        return EncodeResponse(
            embeddings=embeddings.tolist(),
            count=len(request.texts)
        )
    except Exception as e:
        logger.error(f"ç·¨ç¢¼å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/retrieve", response_model=RetrieveResponse)
async def retrieve(request: RetrieveRequest):
    """
    æª¢ç´¢ç›¸ä¼¼çš„è¨˜æ†¶
    
    è¼¸å…¥ï¼š
    {
        "query": "æŸ¥è©¢æ–‡æœ¬",
        "memories": [
            {"id": 1, "content": "è¨˜æ†¶1"},
            {"id": 2, "content": "è¨˜æ†¶2"},
            ...
        ],
        "top_k": 5,
        "threshold": 0.5
    }
    
    è¼¸å‡ºï¼š
    {
        "results": [
            {"id": 1, "content": "è¨˜æ†¶1", "score": 0.85},
            ...
        ],
        "count": 3
    }
    """
    if model is None:
        raise HTTPException(status_code=503, detail="æ¨¡å‹æœªåŠ è¼‰")
    
    try:
        # ç·¨ç¢¼æŸ¥è©¢
        query_embedding = model.encode(request.query, convert_to_tensor=False)
        
        # ç·¨ç¢¼æ‰€æœ‰è¨˜æ†¶
        memory_contents = [m.get("content", "") for m in request.memories]
        memory_embeddings = model.encode(memory_contents, convert_to_tensor=False)
        
        # è¨ˆç®—ç›¸ä¼¼åº¦
        from sklearn.metrics.pairwise import cosine_similarity
        similarities = cosine_similarity([query_embedding], memory_embeddings)[0]
        
        # æ’åºä¸¦ç¯©é¸
        results = []
        for idx, score in enumerate(similarities):
            if score >= request.threshold:
                result = request.memories[idx].copy()
                result["score"] = float(score)
                results.append(result)
        
        # æŒ‰ç›¸ä¼¼åº¦æ’åºï¼Œå– top_k
        results.sort(key=lambda x: x["score"], reverse=True)
        results = results[:request.top_k]
        
        return RetrieveResponse(
            results=results,
            count=len(results)
        )
    except Exception as e:
        logger.error(f"æª¢ç´¢å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/batch-encode")
async def batch_encode(request: EncodeRequest):
    """
    æ‰¹é‡ç·¨ç¢¼ï¼ˆæ”¯æŒå¤§é‡æ–‡æœ¬ï¼‰
    """
    if model is None:
        raise HTTPException(status_code=503, detail="æ¨¡å‹æœªåŠ è¼‰")
    
    try:
        embeddings = model.encode(request.texts, convert_to_tensor=False, batch_size=32)
        return {
            "embeddings": embeddings.tolist(),
            "count": len(request.texts),
            "batch_size": 32
        }
    except Exception as e:
        logger.error(f"æ‰¹é‡ç·¨ç¢¼å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    import uvicorn
    logger.info("ğŸš€ Brain Server å•Ÿå‹•åœ¨ http://localhost:8000")
    logger.info("ğŸ“š API æ–‡æª”ï¼šhttp://localhost:8000/docs")
    uvicorn.run(app, host="0.0.0.0", port=8000)
